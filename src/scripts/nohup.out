Config: --------------------------------
Namespace(d_model=64, num_layers=0, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
Config: --------------------------------
Namespace(d_model=32, num_layers=3, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=32, num_layers=2, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
Config: --------------------------------
Namespace(d_model=32, num_layers=1, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=32, num_layers=2, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
ModuleNotFoundError: No module named 'slidingWindows'
ModuleNotFoundError: No module named 'slidingWindows'
ModuleNotFoundError: No module named 'slidingWindows'
ModuleNotFoundError: No module named 'slidingWindows'
ModuleNotFoundError: No module named 'slidingWindows'





During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:





Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
    from src.utils.slidingWindows import find_length_rank
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
    from statsmodels.tsa.stattools import acf
    from statsmodels.tsa.stattools import acf
    from statsmodels.tsa.stattools import acf
    from statsmodels.tsa.stattools import acf
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
    from statsmodels.tsa.stattools import acf
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
    from statsmodels.tools._test_runner import PytestTester
    from statsmodels.tools._test_runner import PytestTester
    from statsmodels.tools._test_runner import PytestTester
    from statsmodels.tools._test_runner import PytestTester
    from statsmodels.tools._test_runner import PytestTester
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
    from .tools import add_constant, categorical
    from .tools import add_constant, categorical
    from .tools import add_constant, categorical
    from .tools import add_constant, categorical
    from .tools import add_constant, categorical
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 5, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 5, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 5, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 5, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 5, in <module>
    import pandas as pd
    import pandas as pd
    import pandas as pd
    import pandas as pd
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
    import pandas as pd
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
    from pandas.core.api import (
    from pandas.core.api import (
    from pandas.core.api import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/api.py", line 47, in <module>
    from pandas.core.api import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/api.py", line 47, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/api.py", line 47, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/api.py", line 47, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/api.py", line 47, in <module>
    from pandas.core.groupby import (
    from pandas.core.groupby import (
    from pandas.core.groupby import (
    from pandas.core.groupby import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
    from pandas.core.groupby.generic import (
    from pandas.core.groupby.generic import (
    from pandas.core.groupby.generic import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py", line 68, in <module>
    from pandas.core.groupby.generic import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py", line 68, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py", line 68, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py", line 68, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py", line 68, in <module>
    from pandas.core.frame import DataFrame
    from pandas.core.frame import DataFrame
    from pandas.core.frame import DataFrame
    from pandas.core.frame import DataFrame
    from pandas.core.frame import DataFrame
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py", line 149, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py", line 149, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py", line 149, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py", line 149, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py", line 149, in <module>
    from pandas.core.generic import (
    from pandas.core.generic import (
    from pandas.core.generic import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py", line 175, in <module>
    from pandas.core.generic import (
    from pandas.core.generic import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py", line 175, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py", line 175, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py", line 184, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py", line 175, in <module>
    from pandas.core.internals import (
    from pandas.core.internals import (
    from pandas.core.internals import (
    from pandas.core.methods.describe import describe_ndframe
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/__init__.py", line 1, in <module>
    from pandas.core.internals import (
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/__init__.py", line 10, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/__init__.py", line 2, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/methods/describe.py", line 39, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/__init__.py", line 1, in <module>
    from pandas.core.reshape.concat import concat
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1532, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1506, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1609, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1652, in _fill_cache
KeyboardInterrupt
    from pandas.core.internals.api import make_block  # 2023-09-18 pyarrow uses this
    from pandas.core.internals.concat import concatenate_managers
    from pandas.core.internals.array_manager import (
    from pandas.core.internals.api import make_block  # 2023-09-18 pyarrow uses this
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/array_manager.py", line 86, in <module>
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/api.py", line 25, in <module>
  File "<frozen importlib._bootstrap>", line 911, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
KeyboardInterrupt
  File "<frozen importlib._bootstrap_external>", line 1532, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1506, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1609, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1652, in _fill_cache
KeyboardInterrupt
    from pandas.core.internals.blocks import (
    from pandas.core.internals.managers import make_na_array
KeyboardInterrupt
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py", line 89, in <module>
    from pandas.core.internals.ops import (
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1532, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1506, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1605, in find_spec
  File "<frozen importlib._bootstrap_external>", line 147, in _path_stat
KeyboardInterrupt
Config: --------------------------------
Namespace(d_model=64, num_layers=2, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=64, num_layers=2, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=64, num_layers=0, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
    from slidingWindows import find_length_rank
ModuleNotFoundError: No module named 'slidingWindows'

During handling of the above exception, another exception occurred:

    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
ModuleNotFoundError: No module named 'slidingWindows'
ModuleNotFoundError: No module named 'slidingWindows'


During handling of the above exception, another exception occurred:
During handling of the above exception, another exception occurred:
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool


Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
    from statsmodels.tsa.stattools import acf
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
Current project path:  /public/home/202220143416/projects/STAND/src/exp
Current working directory:  /public/home/202220143416/projects/STAND/src/exp
Skipping completed task: PSM, 0.5, 32, 16, 0, 0
Skipping completed task: PSM, 0.5, 32, 16, 0, 1
Skipping completed task: PSM, 0.5, 32, 16, 1, 0
Skipping completed task: PSM, 0.5, 32, 16, 1, 1
Skipping completed task: PSM, 0.5, 32, 16, 2, 0
Skipping completed task: PSM, 0.5, 32, 16, 2, 1
Skipping completed task: PSM, 0.5, 32, 16, 3, 0
Skipping completed task: PSM, 0.5, 32, 16, 3, 1
Skipping completed task: PSM, 0.5, 32, 32, 0, 0
Skipping completed task: PSM, 0.5, 32, 32, 0, 1
Skipping completed task: PSM, 0.5, 32, 32, 1, 0
Skipping completed task: PSM, 0.5, 32, 32, 1, 1
Skipping completed task: PSM, 0.5, 32, 32, 2, 0
Skipping completed task: PSM, 0.5, 32, 32, 2, 1
Skipping completed task: PSM, 0.5, 32, 32, 3, 0
Skipping completed task: PSM, 0.5, 32, 32, 3, 1
Skipping completed task: PSM, 0.5, 32, 64, 0, 0
Skipping completed task: PSM, 0.5, 32, 64, 0, 1
Skipping completed task: PSM, 0.5, 32, 64, 1, 0
Skipping completed task: PSM, 0.5, 32, 64, 1, 1
Skipping completed task: PSM, 0.5, 32, 64, 2, 0
Skipping completed task: PSM, 0.5, 32, 64, 2, 1
Skipping completed task: PSM, 0.5, 32, 64, 3, 0
Skipping completed task: PSM, 0.5, 32, 64, 3, 1
Skipping completed task: PSM, 0.5, 32, 128, 0, 0
Skipping completed task: PSM, 0.5, 32, 128, 0, 1
Skipping completed task: PSM, 0.5, 32, 128, 1, 0
Skipping completed task: PSM, 0.5, 32, 128, 1, 1
Skipping completed task: PSM, 0.5, 32, 128, 2, 0
Skipping completed task: PSM, 0.5, 32, 128, 2, 1
Skipping completed task: PSM, 0.5, 32, 128, 3, 0
Skipping completed task: PSM, 0.5, 32, 128, 3, 1
Skipping completed task: PSM, 0.5, 32, 256, 0, 0
Skipping completed task: PSM, 0.5, 32, 256, 0, 1
Skipping completed task: PSM, 0.5, 32, 256, 1, 0
Skipping completed task: PSM, 0.5, 32, 256, 1, 1
Skipping completed task: PSM, 0.5, 32, 256, 2, 0
Skipping completed task: PSM, 0.5, 32, 256, 2, 1
Skipping completed task: PSM, 0.5, 32, 256, 3, 0
Skipping completed task: PSM, 0.5, 32, 256, 3, 1
Skipping completed task: PSM, 0.5, 64, 16, 0, 0
Skipping completed task: PSM, 0.5, 64, 16, 0, 1
Skipping completed task: PSM, 0.5, 64, 16, 1, 0
Skipping completed task: PSM, 0.5, 64, 16, 1, 1
Skipping completed task: PSM, 0.5, 64, 16, 2, 0
Skipping completed task: PSM, 0.5, 64, 16, 2, 1
Skipping completed task: PSM, 0.5, 64, 16, 3, 0
Skipping completed task: PSM, 0.5, 64, 16, 3, 1
Skipping completed task: PSM, 0.5, 64, 32, 0, 0
Skipping completed task: PSM, 0.5, 64, 32, 0, 1
Skipping completed task: PSM, 0.5, 64, 32, 1, 0
Skipping completed task: PSM, 0.5, 64, 32, 1, 1
Skipping completed task: PSM, 0.5, 64, 32, 2, 0
Skipping completed task: PSM, 0.5, 64, 32, 2, 1
Skipping completed task: PSM, 0.5, 64, 32, 3, 0
Skipping completed task: PSM, 0.5, 64, 32, 3, 1
Skipping completed task: PSM, 0.5, 64, 64, 0, 0
Skipping completed task: PSM, 0.5, 64, 64, 0, 1
Skipping completed task: PSM, 0.5, 64, 64, 1, 0
Skipping completed task: PSM, 0.5, 64, 64, 1, 1
Skipping completed task: PSM, 0.5, 64, 64, 2, 0
Skipping completed task: PSM, 0.5, 64, 64, 2, 1
Skipping completed task: PSM, 0.5, 64, 64, 3, 0
Skipping completed task: PSM, 0.5, 64, 64, 3, 1
Skipping completed task: PSM, 0.5, 64, 128, 0, 0
Skipping completed task: PSM, 0.5, 64, 128, 0, 1
Skipping completed task: PSM, 0.5, 64, 128, 1, 0
Skipping completed task: PSM, 0.5, 64, 128, 1, 1
Skipping completed task: PSM, 0.5, 64, 128, 2, 0
Skipping completed task: PSM, 0.5, 64, 128, 2, 1
Skipping completed task: PSM, 0.5, 64, 128, 3, 0
Skipping completed task: PSM, 0.5, 64, 128, 3, 1
Skipping completed task: PSM, 0.5, 64, 256, 0, 0
Skipping completed task: PSM, 0.5, 64, 256, 0, 1
Skipping completed task: PSM, 0.5, 64, 256, 1, 0
Skipping completed task: PSM, 0.5, 64, 256, 1, 1
Skipping completed task: PSM, 0.5, 64, 256, 2, 0
Skipping completed task: PSM, 0.5, 64, 256, 2, 1
Skipping completed task: PSM, 0.5, 64, 256, 3, 0
Skipping completed task: PSM, 0.5, 64, 256, 3, 1
Skipping completed task: PSM, 0.5, 128, 16, 0, 0
Skipping completed task: PSM, 0.5, 128, 16, 0, 1
Skipping completed task: PSM, 0.5, 128, 16, 1, 0
Skipping completed task: PSM, 0.5, 128, 16, 1, 1
Skipping completed task: PSM, 0.5, 128, 16, 2, 0
Skipping completed task: PSM, 0.5, 128, 16, 2, 1
Skipping completed task: PSM, 0.5, 128, 16, 3, 0
Skipping completed task: PSM, 0.5, 128, 16, 3, 1
Skipping completed task: PSM, 0.5, 128, 32, 0, 0
Skipping completed task: PSM, 0.5, 128, 32, 0, 1
Skipping completed task: PSM, 0.5, 128, 32, 1, 0
Skipping completed task: PSM, 0.5, 128, 32, 1, 1
Skipping completed task: PSM, 0.5, 128, 32, 2, 0
Skipping completed task: PSM, 0.5, 128, 32, 2, 1
Skipping completed task: PSM, 0.5, 128, 32, 3, 0
Skipping completed task: PSM, 0.5, 128, 32, 3, 1
Skipping completed task: PSM, 0.5, 128, 64, 0, 0
Skipping completed task: PSM, 0.5, 128, 64, 0, 1
Skipping completed task: PSM, 0.5, 128, 64, 1, 0
Skipping completed task: PSM, 0.5, 128, 64, 1, 1
Skipping completed task: PSM, 0.5, 128, 64, 2, 0
Skipping completed task: PSM, 0.5, 128, 64, 2, 1
Skipping completed task: PSM, 0.5, 128, 64, 3, 0
Skipping completed task: PSM, 0.5, 128, 64, 3, 1
Skipping completed task: PSM, 0.5, 128, 128, 0, 0
Skipping completed task: PSM, 0.5, 128, 128, 0, 1
Skipping completed task: PSM, 0.5, 128, 128, 1, 0
Skipping completed task: PSM, 0.5, 128, 128, 1, 1
Skipping completed task: PSM, 0.5, 128, 128, 2, 0
Skipping completed task: PSM, 0.5, 128, 128, 2, 1
Skipping completed task: PSM, 0.5, 128, 128, 3, 0
Skipping completed task: PSM, 0.5, 128, 128, 3, 1
Skipping completed task: PSM, 0.5, 128, 256, 0, 0
Skipping completed task: PSM, 0.5, 128, 256, 0, 1
Skipping completed task: PSM, 0.5, 128, 256, 1, 0
Skipping completed task: PSM, 0.5, 128, 256, 1, 1
Skipping completed task: PSM, 0.5, 128, 256, 2, 0
Skipping completed task: PSM, 0.5, 128, 256, 2, 1
Skipping completed task: PSM, 0.5, 128, 256, 3, 0
Skipping completed task: PSM, 0.5, 128, 256, 3, 1
Skipping completed task: SWAT, 0.5, 32, 16, 0, 0
Skipping completed task: SWAT, 0.5, 32, 16, 0, 1
Skipping completed task: SWAT, 0.5, 32, 16, 1, 0
Skipping completed task: SWAT, 0.5, 32, 16, 1, 1
Skipping completed task: SWAT, 0.5, 32, 16, 2, 0
Skipping completed task: SWAT, 0.5, 32, 16, 2, 1
Skipping completed task: SWAT, 0.5, 32, 16, 3, 0
Skipping completed task: SWAT, 0.5, 32, 16, 3, 1
Skipping completed task: SWAT, 0.5, 32, 32, 0, 0
Skipping completed task: SWAT, 0.5, 32, 32, 0, 1
Skipping completed task: SWAT, 0.5, 32, 32, 1, 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 1
Running experiment for model: STAND, dataset: SWAT
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 0
Running experiment for model: STAND, dataset: SWAT
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 1
Running experiment for model: STAND, dataset: SWAT
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 0
Running experiment for model: STAND, dataset: SWAT
Skipping completed task: SWAT, 0.5, 32, 32, 3, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 0
Running experiment for model: STAND, dataset: SWAT
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 1
Skipping completed task: WADI, 0.5, 32, 16, 0, 0
Skipping completed task: WADI, 0.5, 32, 16, 0, 1
Skipping completed task: WADI, 0.5, 32, 16, 1, 0
Skipping completed task: WADI, 0.5, 32, 16, 1, 1
Skipping completed task: WADI, 0.5, 32, 16, 2, 0
Skipping completed task: WADI, 0.5, 32, 16, 2, 1
Skipping completed task: WADI, 0.5, 32, 16, 3, 0
Skipping completed task: WADI, 0.5, 32, 16, 3, 1
Skipping completed task: WADI, 0.5, 32, 32, 0, 0
Skipping completed task: WADI, 0.5, 32, 32, 0, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 1
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 0, 0
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 0, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 1, bidirectional: 0
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 1, 1
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 2, 0
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 2, 1
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 3, 0
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 16, 3, 1
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 32, 0, 0
Skipping completed task: NIPS_TS_Swan, 0.5, 32, 32, 0, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 0, bidirectional: 0
Skipping completed task: NIPS_TS_Water, 0.5, 32, 16, 0, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 2, bidirectional: 0
Skipping completed task: NIPS_TS_Water, 0.5, 32, 16, 2, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 16, num_layers: 3, bidirectional: 0
Skipping completed task: NIPS_TS_Water, 0.5, 32, 16, 3, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 0, bidirectional: 0
Skipping completed task: NIPS_TS_Water, 0.5, 32, 32, 0, 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 32, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 64, d_model: 256, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 16, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 32, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 64, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 128, num_layers: 3, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 0, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 1, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 2, bidirectional: 1
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 0
Submitting STAND with train_test_split: 0.5, win_size: 128, d_model: 256, num_layers: 3, bidirectional: 1
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
Traceback (most recent call last):
    from src.utils.slidingWindows import find_length_rank
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
  File "/public/home/202220143416/projects/STAND/src/scripts/run_supervised_abl.py", line 118, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
    from statsmodels.tsa.stattools import acf
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
    from statsmodels.tsa.stattools import acf
    from statsmodels.tools._test_runner import PytestTester
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from .tools import add_constant, categorical
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 6, in <module>
    from statsmodels.tools._test_runner import PytestTester
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
    from statsmodels.tools._test_runner import PytestTester
    import scipy.linalg
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 204, in <module>
    from .tools import add_constant, categorical
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 6, in <module>
    from .tools import add_constant, categorical
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 6, in <module>
    import scipy.linalg
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 204, in <module>
    import scipy.linalg
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 204, in <module>
    for future in concurrent.futures.as_completed(futures):
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 243, in as_completed
    from ._cythonized_array_utils import *
    from ._cythonized_array_utils import *
    from ._cythonized_array_utils import *
  File "scipy/linalg/_cythonized_array_utils.pyx", line 11, in init scipy.linalg._cythonized_array_utils
  File "scipy/linalg/_cythonized_array_utils.pyx", line 11, in init scipy.linalg._cythonized_array_utils
  File "scipy/linalg/_cythonized_array_utils.pyx", line 11, in init scipy.linalg._cythonized_array_utils
    waiter.event.wait(wait_timeout)
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 655, in wait
Config: --------------------------------
Namespace(d_model=64, num_layers=1, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=64, num_layers=1, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 4, in <module>
    from slidingWindows import find_length_rank
    from slidingWindows import find_length_rank
ModuleNotFoundError: No module named 'slidingWindows'

ModuleNotFoundError: No module named 'slidingWindows'
During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:
Traceback (most recent call last):

  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 22, in <module>
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
    from src.utils.model_wrapper import run_Supervise_AD, Supervise_AD_Pool
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/model_wrapper.py", line 11, in <module>
    from src.utils.slidingWindows import find_length_rank
    from src.utils.slidingWindows import find_length_rank
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
  File "/public/home/202220143416/projects/STAND/src/utils/slidingWindows.py", line 1, in <module>
    from statsmodels.tsa.stattools import acf
    from statsmodels.tsa.stattools import acf
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/__init__.py", line 1, in <module>
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
    from statsmodels.compat.patsy import monkey_patch_cat_dtype
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/compat/__init__.py", line 1, in <module>
    from statsmodels.tools._test_runner import PytestTester
    from statsmodels.tools._test_runner import PytestTester
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/__init__.py", line 1, in <module>
    from .tools import add_constant, categorical
    from .tools import add_constant, categorical
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 6, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/statsmodels/tools/tools.py", line 6, in <module>
    import scipy.linalg
    import scipy.linalg
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 204, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 204, in <module>
    from ._cythonized_array_utils import *
    from ._cythonized_array_utils import *
  File "scipy/linalg/_cythonized_array_utils.pyx", line 11, in init scipy.linalg._cythonized_array_utils
  File "scipy/linalg/_cythonized_array_utils.pyx", line 11, in init scipy.linalg._cythonized_array_utils
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py", line 14, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py", line 14, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py", line 14, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py", line 14, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py", line 14, in <module>
    from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,
    from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,
    from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_array_api.py", line 25, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_array_api.py", line 24, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_array_api.py", line 25, in <module>
    from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,
    from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_array_api.py", line 24, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/_array_api.py", line 24, in <module>
    signaled = self._cond.wait(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/scripts/run_supervised_abl.py", line 107, in <module>
    from scipy._lib import array_api_compat
    from scipy._lib.array_api_compat import (
    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_jobs) as executor:
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/__init__.py", line 22, in <module>
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "/public/home/202220143416/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 647, in __exit__
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1532, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1506, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1624, in find_spec
KeyboardInterrupt
    self.shutdown(wait=True)
  File "/public/home/202220143416/miniconda3/lib/python3.12/concurrent/futures/thread.py", line 239, in shutdown
    from scipy._lib.array_api_compat import (
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1532, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1506, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1624, in find_spec
KeyboardInterrupt
    from .common import *  # noqa: F401, F403
    ^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/__init__.py", line 1, in <module>
    from scipy._lib import array_api_compat
    from scipy._lib import array_api_compat
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/__init__.py", line 22, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/__init__.py", line 22, in <module>
    from .common import *  # noqa: F401, F403
    from .common import *  # noqa: F401, F403
    ^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/__init__.py", line 1, in <module>
    ^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/__init__.py", line 1, in <module>
    from ._helpers import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^^
    from ._helpers import *  # noqa: F403
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py", line 30, in <module>
    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py", line 30, in <module>
    from ._helpers import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py", line 30, in <module>
    from ._typing import Array, Device, HasShape, Namespace, SupportsArrayNamespace
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_typing.py", line 99, in <module>
    from ._typing import Array, Device, HasShape, Namespace, SupportsArrayNamespace
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_typing.py", line 126, in <module>
    from ._typing import Array, Device, HasShape, Namespace, SupportsArrayNamespace
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_typing.py", line 99, in <module>
    _DTypeKind: TypeAlias = Literal[
    class DTypesUnsigned(TypedDict):
                            ^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 2915, in __new__
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 524, in __getitem__
    _DTypeKind: TypeAlias = Literal[
    t.join()
                            ^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 1149, in join
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 524, in __getitem__
    self._wait_for_tstate_lock()
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
    return self._getitem(self, *parameters)
    return self._getitem(self, *parameters)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    n: _type_check(tp, msg, module=tp_dict.__module__)
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 395, in inner
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 395, in inner
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 193, in _type_check
    return _caches[func](*args, **kwds)
    return _caches[func](*args, **kwds)
    arg = _type_convert(arg, module=module, allow_special_forms=allow_special_forms)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 785, in Literal
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 781, in Literal
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 171, in _type_convert
    return ForwardRef(arg, module=module, is_class=allow_special_forms)
    return _LiteralGenericAlias(self, parameters)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    parameters = tuple(p for p, _ in _deduplicate(list(_value_and_type_iter(parameters))))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 904, in __init__
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 1275, in __init__
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 317, in _deduplicate
    code = compile(arg_to_compile, '<string>', 'eval')
    def _deduplicate(params, *, unhashable_fallback=False):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    
KeyboardInterrupt
    self.__parameters__ = _collect_parameters(args)
KeyboardInterrupt
                          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/202220143416/miniconda3/lib/python3.12/typing.py", line 285, in _collect_parameters
    elif hasattr(t, '__typing_subst__'):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in: <module 'threading' from '/public/home/202220143416/miniconda3/lib/python3.12/threading.py'>
Traceback (most recent call last):
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 1594, in _shutdown
    atexit_call()
  File "/public/home/202220143416/miniconda3/lib/python3.12/concurrent/futures/thread.py", line 31, in _python_exit
    t.join()
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/public/home/202220143416/miniconda3/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt: 
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Running experiment for model: STAND, dataset: SWAT
Config: --------------------------------
Namespace(d_model=128, num_layers=1, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Config: --------------------------------
Namespace(d_model=128, num_layers=0, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 23, in <module>
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 23, in <module>
    from src.data_utils.SimAD_data_loader2 import get_loader_segment, SupervisedDataset
    from src.data_utils.SimAD_data_loader2 import get_loader_segment, SupervisedDataset
  File "/public/home/202220143416/projects/STAND/src/data_utils/SimAD_data_loader2.py", line 2, in <module>
  File "/public/home/202220143416/projects/STAND/src/data_utils/SimAD_data_loader2.py", line 2, in <module>
    import torch
    import torch
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/torch/__init__.py", line 416, in <module>
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/torch/__init__.py", line 416, in <module>
    from torch._C import *  # noqa: F403
    from torch._C import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^
    ^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 463, in _lock_unlock_module
  File "<frozen importlib._bootstrap>", line 463, in _lock_unlock_module
KeyboardInterrupt
KeyboardInterrupt
Config: --------------------------------
Namespace(d_model=64, num_layers=3, bidirectional=1, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 23, in <module>
    from src.data_utils.SimAD_data_loader2 import get_loader_segment, SupervisedDataset
  File "/public/home/202220143416/projects/STAND/src/data_utils/SimAD_data_loader2.py", line 2, in <module>
    import torch
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/torch/__init__.py", line 416, in <module>
    from torch._C import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 463, in _lock_unlock_module
KeyboardInterrupt
Config: --------------------------------
Namespace(d_model=64, num_layers=3, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 23, in <module>
    from src.data_utils.SimAD_data_loader2 import get_loader_segment, SupervisedDataset
  File "/public/home/202220143416/projects/STAND/src/data_utils/SimAD_data_loader2.py", line 2, in <module>
    import torch
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/torch/__init__.py", line 416, in <module>
    from torch._C import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 463, in _lock_unlock_module
KeyboardInterrupt
Config: --------------------------------
Namespace(d_model=128, num_layers=0, bidirectional=0, model_name='STAND', task_name='supervised', win_size=32, step_size=1, batch_size=128, epochs=10, lr=0.001, model_saving_path='/public/home/202220143416/projects/STAND/model_saving', dataset_path='/public/home/202220143416/projects/FTSAD/datasets', dataset_name='SWAT', if_save=0, index=0, train_test_split=0.5, anomaly_ratio=0.1, train_split_max=0.3, metric_list=['CCE', 'F1', 'Aff-F1', 'UAff-F1', 'AUC-ROC', 'VUS-PR'], quantile=0.95)
Log will be saved to:  /public/home/202220143416/projects/STAND/logs
Traceback (most recent call last):
  File "/public/home/202220143416/projects/STAND/src/exp/supervised.py", line 23, in <module>
    from src.data_utils.SimAD_data_loader2 import get_loader_segment, SupervisedDataset
  File "/public/home/202220143416/projects/STAND/src/data_utils/SimAD_data_loader2.py", line 2, in <module>
    import torch
  File "/public/home/202220143416/miniconda3/lib/python3.12/site-packages/torch/__init__.py", line 416, in <module>
    from torch._C import *  # noqa: F403
    ^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 463, in _lock_unlock_module
KeyboardInterrupt
